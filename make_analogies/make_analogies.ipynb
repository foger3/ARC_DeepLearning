{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from make_analogies_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co = {\"top\": 2,  \"bottom\": 7, \"left\": 7, \"right\": 9}\n",
    "# im = create_image_with_white_rectangle(co, 10)\n",
    "# print(im)\n",
    "# print()\n",
    "# gravity(im, co, \"down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000 #each sample is a trio of images of which each comes in various forms (analogous transformations).\n",
    "img_size = 10\n",
    "all_images = []\n",
    "method_names = [\"Resized\", \"Moved\", \"Rotated\", \"Inverted\", \"Mirrored\", \"Close/Far Corners\", \"Close/Far Edges\", \"Stretched\", \"Shadows\", \"Gravity\"]\n",
    "seed_iteration = 0\n",
    "data = []\n",
    "\n",
    "for i in range(num_samples):    \n",
    "    trios = []\n",
    "    invalid_img = True\n",
    "    while invalid_img:\n",
    "        seed_iteration += 1\n",
    "        np.random.seed(seed_iteration)\n",
    "\n",
    "        #make 3 random images with rectangles\n",
    "        top_lefts = [{\"top\": np.random.randint(1, img_size-1), \"left\": np.random.randint(1, img_size-1)} for _ in range(3)]\n",
    "        bottom_rights = [{\"bottom\": np.random.randint(d[\"top\"] + 1, img_size), \"right\": np.random.randint(d[\"left\"] + 1, img_size)} for d in top_lefts]\n",
    "        coords = [top_left | bottom_right for top_left, bottom_right in zip(top_lefts, bottom_rights)]\n",
    "        trio = [create_image_with_white_rectangle(coord, img_size) for coord in coords]\n",
    "   \n",
    "        #sample parameters for analogies\n",
    "        mirror_horizontal = np.random.choice([True, False])\n",
    "        rotation_degree = np.random.choice([90, 180, 270])\n",
    "        grow_left = np.random.choice([0,0,1,2])\n",
    "        grow_right = np.random.choice([0,0,1,2])\n",
    "        grow_top = np.random.choice([0,0,1,2])\n",
    "        grow_bottom = np.random.choice([0,0,1,2])\n",
    "        move_vertical = np.random.choice([0,1,2])\n",
    "        move_horizontal = np.random.choice([0,1,2])\n",
    "        furthest_edge = np.random.choice([True, False])\n",
    "        furthest_corner = np.random.choice([True, False])\n",
    "        reverse_shadows = np.random.choice([True, False])\n",
    "        gravity_direction = np.random.choice([\"up\",\"down\",\"left\",\"right\"])\n",
    "\n",
    "        # Generate analogies\n",
    "        resizes = [resize_rectangle(img, coord, grow_top, grow_bottom, grow_left, grow_right) for img, coord in zip(trio, coords)]\n",
    "        moves = [move_rectangle(img, move_horizontal, move_vertical)  for img in trio]\n",
    "        rotations = [rotate_image(img, rotation_degree) for img in trio]\n",
    "        inversions = [invert_colors(img)  for img in trio]\n",
    "        mirrors = [mirror_image(img, horizontal=mirror_horizontal) for img in trio]\n",
    "        corner_cells = [paint_corner(img, furthest_corner) for img in trio]\n",
    "        edges = [paint_edge(img, coord, furthest_edge) for img, coord in zip(trio, coords)]\n",
    "        stretches = [stretch_rectangle(img, coord) for img, coord in zip(trio, coords)]\n",
    "        shadows = [draw_shadows(img, coord, reverse_shadows)  for img, coord in zip(trio, coords)]\n",
    "        gravities = [gravity(img, coord, gravity_direction)  for img, coord in zip(trio, coords)]\n",
    "        \n",
    "        #check whether images violate rules (original three include duplicates; initial transformations left the canvas)\n",
    "        if np.array_equal(trio[0], trio[1]) or np.array_equal(trio[0], trio[2]) or np.array_equal(trio[1], trio[2]):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(moves[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(resizes[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        else:\n",
    "            invalid_img = False\n",
    "    \n",
    "    transformed_trios = [resizes, moves, rotations, inversions, mirrors, corner_cells, edges, stretches, shadows, gravities]\n",
    "    data.append([np.stack([trio, transformed_trio]) for transformed_trio in transformed_trios])\n",
    "\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is for reformatting the df; one could e.g. slice off specific data here (e.g., for a test set with new analogies)\n",
    "long_data = data.reshape(data.shape[0]*data.shape[1], data.shape[2], data.shape[3], data.shape[4], data.shape[5])\n",
    "long_data = long_data.reshape(long_data.shape[0], long_data.shape[1] * long_data.shape[2], long_data.shape[3], long_data.shape[4])\n",
    "plot_double_trio(long_data[8]) #first 9 on first dim are same trio and all 9 transformations; then it starts over with second trio\n",
    "nonduplicates = np.unique(long_data, axis=0) #get rid of duplicated tasks; could be stricter by also considering flipped fewshot order as duplicated\n",
    "print(f\"{np.round(100*(1 - nonduplicates.shape[0] / long_data.shape[0]),1)}% double trios were duplicated\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nonduplicates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nonduplicates, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into input (x) and output (y)\n",
    "x_data = nonduplicates[:, :-1, :, :] / 255 # All but the last channel\n",
    "y_data = nonduplicates[:, -1, :, :] / 255  # Only the last channel\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_data = torch.from_numpy(x_data).float()\n",
    "y_data = torch.from_numpy(y_data).float()\n",
    "\n",
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.005, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting tensors\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic feed forward test\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(5 * 10 * 10, 150) \n",
    "        self.relu1 = nn.ReLU()  \n",
    "        self.fc2 = nn.Linear(150, 150) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(150, 150) \n",
    "        self.relu3 = nn.ReLU() \n",
    "        self.fc4 = nn.Linear(150, 10 * 10) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.view(-1, 10, 10)  # Reshape the output to be 10x10\n",
    "\n",
    "# Create an instance of the model\n",
    "model = FullyConnectedNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_outputs = model(x_train)\n",
    "    loss = criterion(train_outputs, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(x_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Test: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Nr params: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exmp = 0\n",
    "with torch.no_grad():\n",
    "    y  = y_test[plot_exmp].expand(1, y_test[plot_exmp].shape[0], y_test[plot_exmp].shape[1])\n",
    "    example = torch.row_stack((x_test[plot_exmp], y))\n",
    "    plot_double_trio(example)\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.title(\"Non-binarized Output\")\n",
    "    plt.imshow(model(x_test[plot_exmp].unsqueeze(0))[0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
