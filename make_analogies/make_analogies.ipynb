{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to decrease learning rate in last 5 epochs\n",
    "make_new_data = False\n",
    "train_new_model = True\n",
    "log_wandb = True\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import pickle\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from make_analogies_functions import *\n",
    "\n",
    "num_samples = 100000 #each sample is a trio of images of which each comes in various forms (analogous transformations).\n",
    "img_size = 10\n",
    "pairs_per_task = 3\n",
    "shape = \"O\" #I or L or O or T\n",
    "all_images = []\n",
    "analogy_names = [\"Grown\", \"Moved\", \"Rotated\", \"Inverted\", \"Mirrored\", \"Close_Far Corners\", \"Close_Far Edges\", \"Stretched\", \"Shadows\", \"Gravity\", \"Count\"]\n",
    "seed_iteration = 0\n",
    "rel_test_size  = 0.01\n",
    "num_epochs = 70\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "use_lr_scheduler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_new_data:\n",
    "    data = []\n",
    "    analogy_index_detailed = []\n",
    "    for i in range(num_samples):    \n",
    "        trios = []\n",
    "        invalid_img = True\n",
    "        while invalid_img:\n",
    "            seed_iteration += 1\n",
    "            np.random.seed(seed_iteration)\n",
    "\n",
    "            #make 3 random images with Is\n",
    "            trio = [create_image(img_size = img_size, shape = shape) for _ in range(pairs_per_task)]\n",
    "\n",
    "            #sample parameters for analogies\n",
    "            mirror_horizontal = np.random.choice([True, False])\n",
    "            rotation_degree = np.random.choice([90, 180, 270])\n",
    "            grow_left = np.random.choice([0,1])\n",
    "            grow_right = np.random.choice([0,1])\n",
    "            grow_top = np.random.choice([0,1])\n",
    "            grow_bottom = np.random.choice([0,1])\n",
    "            possible_growths = [(0, 1, 0, 0), (1, 0, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1)]\n",
    "            growth_index = np.random.choice(len(possible_growths))  # Choose an index from the list\n",
    "            grow_left, grow_right, grow_top, grow_bottom = possible_growths[growth_index]\n",
    "            possible_moves = [(0, 1), (1, 0), (-1, 0), (0, -1)]\n",
    "            move_index = np.random.choice(len(possible_moves))  # Choose an index from the list\n",
    "            move_vertical, move_horizontal = possible_moves[move_index]\n",
    "            furthest_edge = np.random.choice([True, False])\n",
    "            furthest_corner = np.random.choice([True, False])\n",
    "            reverse_shadows = np.random.choice([True, False])\n",
    "            gravity_direction = np.random.choice([\"up\",\"down\",\"left\",\"right\"])\n",
    "            count_left_right = np.random.choice([True, False])\n",
    "            count_top_bottom = np.random.choice([True, False])\n",
    "\n",
    "            # Generate analogies\n",
    "            growths = [grow(img, grow_top, grow_bottom, grow_left, grow_right) for img in trio]\n",
    "            moves = [move(img, move_horizontal, move_vertical)  for img in trio]\n",
    "            rotations = [rotate_image(img, rotation_degree) for img in trio]\n",
    "            inversions = [invert_colors(img)  for img in trio]\n",
    "            mirrors = [mirror_image(img, horizontal=mirror_horizontal) for img in trio]\n",
    "            corner_cells = [paint_corner(img, furthest_corner) for img in trio]\n",
    "            edges = [paint_edge(img, furthest_edge) for img in trio]\n",
    "            stretches = [stretch(img) for img in trio]\n",
    "            shadows = [draw_shadows(img, reverse_shadows)  for img in trio]\n",
    "            gravities = [gravity(img, gravity_direction)  for img in trio]\n",
    "            counts = [count_pixels(img, count_left_right, count_top_bottom) for img in trio]\n",
    "   \n",
    "            #check whether images violate rules (original three include duplicates; initial transformations left the canvas)\n",
    "            if np.array_equal(trio[0], trio[1]) or np.array_equal(trio[0], trio[2]) or np.array_equal(trio[1], trio[2]):\n",
    "                invalid_img = True\n",
    "            elif invalid_matrix(moves[0], img_size, img_size, 1):\n",
    "                invalid_img = True\n",
    "            elif invalid_matrix(growths[0], img_size, img_size, 1):\n",
    "                invalid_img = True\n",
    "            else:\n",
    "                invalid_img = False\n",
    "\n",
    "        transformed_trios = [growths, moves, rotations, inversions, mirrors, corner_cells, edges, stretches, shadows, gravities, counts]\n",
    "        data.append([np.stack([trio, transformed_trio]) for transformed_trio in transformed_trios])\n",
    "        analogy_index_detailed.extend([f\"grow_{possible_growths[growth_index]}\",f\"move_{possible_moves[move_index]}\",f\"rotate_{rotation_degree}\",\"inversion\",f\"mirror_{mirror_horizontal}\",f\"corner_{furthest_corner}\",f\"edge_{furthest_edge}\",\"stretch\",f\"shadows_{reverse_shadows}\",f\"gravity_{gravity_direction}\",f\"count_{count_left_right}_{count_top_bottom}\"])\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    long_data = data.reshape(data.shape[0]*data.shape[1], data.shape[2], data.shape[3], data.shape[4], data.shape[5])\n",
    "    long_data = long_data.reshape(long_data.shape[0], long_data.shape[1] * long_data.shape[2], long_data.shape[3], long_data.shape[4])\n",
    "    analogy_index = np.tile(analogy_names, num_samples)\n",
    "    nonduplicates, unique_ind = np.unique(long_data, axis=0, return_index=True) #get rid of duplicated tasks; could be stricter by also considering flipped fewshot orders as duplicated\n",
    "    analogy_index = analogy_index[unique_ind]\n",
    "    print(f\"{np.round(100*(1 - nonduplicates.shape[0] / long_data.shape[0]), 1)}% double trios were duplicated\") \n",
    "    print(long_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_new_data:\n",
    "    with open(f\"nonduplicates_{shape}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nonduplicates, file=f)\n",
    "    with open(f\"analogy_index_{shape}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(analogy_index, file=f)\n",
    "    with open(f\"analogy_index_detailed_{shape}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(analogy_index_detailed, file=f)\n",
    "else:\n",
    "    with open(f\"nonduplicates_{shape}.pkl\", \"rb\") as f:\n",
    "        nonduplicates = pickle.load(file=f)\n",
    "    with open(f\"analogy_index_{shape}.pkl\", \"rb\") as f:\n",
    "        analogy_index = pickle.load(file=f)\n",
    "    with open(f\"analogy_index_detailed_{shape}.pkl\", \"rb\") as f:\n",
    "        analogy_index_detailed = pickle.load(file=f)\n",
    "\n",
    "\n",
    "# for shape2 in [\"O\", \"T\"]:\n",
    "#     with open(f\"nonduplicates_{shape2}.pkl\", \"rb\") as f:\n",
    "#         nonduplicates = np.concatenate([nonduplicates, pickle.load(file=f)])\n",
    "#     with open(f\"analogy_index_{shape2}.pkl\", \"rb\") as f:\n",
    "#         analogy_index = np.concatenate([analogy_index, pickle.load(file=f)])\n",
    "#     with open(f\"analogy_index_detailed_{shape2}.pkl\", \"rb\") as f:\n",
    "#         analogy_index_detailed = pickle.load(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =900\n",
    "print(analogy_index[n])\n",
    "plot_double_trio(nonduplicates[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input (x) and output (y)\n",
    "x_data = nonduplicates[:, :-1, :, :] / 255 # All but the last channel\n",
    "y_data = nonduplicates[:, -1, :, :] / 255  # Only the last channel\n",
    "x_data = torch.from_numpy(x_data).float()\n",
    "y_data = torch.from_numpy(y_data).float()\n",
    "x_train, x_test, y_train, y_test, analogy_train, analogy_test = train_test_split(x_data, y_data, analogy_index, test_size=rel_test_size, random_state=42)\n",
    "print(f\"x_train: {x_train.shape},\\ny_train: {y_train.shape},\\nx_test: {x_test.shape},\\ny_test: {y_test.shape}\")\n",
    "print(f\"train analogies: {analogy_train[0:3]}\")\n",
    "print(f\"test analogies: {analogy_test[0:3]}\")\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if train_new_model and log_wandb:\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Get current date and time\n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Format the datetime object as a string\n",
    "    current_datetime_string = current_datetime.strftime(\"%Y-%m-%d %H\")\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"simpleARC\",\n",
    "        name = f\"{shape}_{current_datetime_string}\",\n",
    "        config={\n",
    "        \n",
    "        \"architecture\": FullyConnectedNN,\n",
    "        \"shape\": shape,\n",
    "        \"img_size\": img_size,\n",
    "        \"pairs_per_task\": pairs_per_task,\n",
    "        \"analogies\": analogy_names,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"use_lr_scheduler\": use_lr_scheduler,\n",
    "        \"rel_test_size\": rel_test_size,\n",
    "        \"num_samples\": num_samples\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "if train_new_model:\n",
    "    model = FullyConnectedNN().to(device)\n",
    "    print(f\"Nr params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "    if use_lr_scheduler:\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, end_factor=0.1, total_iters=num_epochs, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for (inputs, labels) in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            train_outputs = model(inputs)\n",
    "            loss = criterion(train_outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if use_lr_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        test_metrics = get_test_metrics(x_test, y_test, model, criterion, analogy_test, True)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Test: {test_metrics[\"test loss\"]:.4f}, %solved: {test_metrics[\"percent_solved\"]:.2f}')\n",
    "        if log_wandb:\n",
    "            wandb.log({\"epoch\": epoch + 1, \"train Loss\": loss.item()} | test_metrics)\n",
    "\n",
    "    torch.save(model.state_dict(), f'model_trained_on_{shape}.pth')\n",
    "else:\n",
    "    model = FullyConnectedNN()\n",
    "    model.load_state_dict(torch.load(f'model_trained_on_{shape}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exmp = 0\n",
    "with torch.inference_mode():\n",
    "    print(\"Test set example:\")\n",
    "    y  = y_test[plot_exmp].expand(1, y_test[plot_exmp].shape[0], y_test[plot_exmp].shape[1])\n",
    "    example = torch.row_stack((x_test[plot_exmp], y))\n",
    "    plot_double_trio(example)\n",
    "\n",
    "    print(\"Prediction:\")\n",
    "    tensor = model(x_test[plot_exmp].unsqueeze(0))[0]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 3))  # 1 row, 2 columns\n",
    "    axs[0].set_title(\"Non-binarized (grayscale)\")\n",
    "    axs[0].imshow(tensor, cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].set_title(\"Binarized (b/w)\")\n",
    "    axs[1].imshow(torch.round(tensor), cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Most similar training case:\")\n",
    "    distances = [torch.sum(torch.abs(x_test[plot_exmp] - np.array(x_train[i]))).item() for i in range(x_train.shape[0])]\n",
    "    sim_index = np.argmin(distances)\n",
    "    y  = y_train[sim_index].expand(1, y_train[sim_index].shape[0], y_train[sim_index].shape[1])\n",
    "    plot_double_trio(torch.row_stack((x_train[sim_index], y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on all shapes (e.g. differently shaped figures)\n",
    "for test_shape in [\"I\", \"L\", \"O\", \"T\"]:\n",
    "    with open(f\"nonduplicates_{test_shape}.pkl\", \"rb\") as f:\n",
    "        added_test_data = pickle.load(file=f)\n",
    "    with open(f\"analogy_index_{test_shape}.pkl\", \"rb\") as f:\n",
    "        analogies_from_added_data = pickle.load(file=f)\n",
    "    added_x_data = added_test_data[:, :-1, :, :] / 255 # All but the last channel\n",
    "    added_y_data = added_test_data[:, -1, :, :] / 255  # Only the last channel\n",
    "    added_x_data = torch.from_numpy(added_x_data).float()\n",
    "    added_y_data = torch.from_numpy(added_y_data).float()\n",
    "    metrics = get_test_metrics(added_x_data, added_y_data, model, nn.BCELoss(), analogies_from_added_data, True)\n",
    "    print(metrics)\n",
    "    if log_wandb:\n",
    "        wandb.log({f\"{test_shape}_{key}\": value for key, value in metrics.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect prediction on other datafile (e.g. differently shaped figures)\n",
    "test_shape = \"L\"\n",
    "with open(f\"nonduplicates_{test_shape}.pkl\", \"rb\") as f:\n",
    "    added_test_data = pickle.load(file=f)\n",
    "with open(f\"analogy_index_{test_shape}.pkl\", \"rb\") as f:\n",
    "    analogies_from_added_data = pickle.load(file=f)\n",
    "added_x_data = added_test_data[:, :-1, :, :] / 255 # All but the last channel\n",
    "added_y_data = added_test_data[:, -1, :, :] / 255  # Only the last channel\n",
    "added_x_data = torch.from_numpy(added_x_data).float()\n",
    "added_y_data = torch.from_numpy(added_y_data).float()\n",
    "plot_exmp = 0\n",
    "with torch.inference_mode():\n",
    "    print(\"Example from additional dataset:\")\n",
    "    added_y  = added_y_data[plot_exmp].expand(1, added_y_data[plot_exmp].shape[0], added_y_data[plot_exmp].shape[1])\n",
    "    example = torch.row_stack((added_x_data[plot_exmp], added_y))\n",
    "    plot_double_trio(example)\n",
    "    print(\"Prediction:\")\n",
    "    tensor = model(added_x_data[plot_exmp].unsqueeze(0))[0]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 3))  # 1 row, 2 columns\n",
    "    axs[0].set_title(\"Non-binarized (grayscale)\")\n",
    "    axs[0].imshow(tensor, cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].set_title(\"Binarized (b/w)\")\n",
    "    axs[1].imshow(torch.round(tensor), cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
