{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "\n",
    "from make_analogies_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 9, 2, 3, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000 #each sample is a trio of images of which each comes in various forms (analogous transformations).\n",
    "img_size = 10\n",
    "all_images = []\n",
    "method_names = [\"Resized\", \"Moved\", \"Rotated\", \"Inverted\", \"Mirrored\", \"Close/Far Corners\", \"Close/Far Edges\", \"Stretched\", \"Shadows\"]\n",
    "seed_iteration = 0\n",
    "data = []\n",
    "\n",
    "for i in range(num_samples):    \n",
    "    trios = []\n",
    "    invalid_img = True\n",
    "    while invalid_img:\n",
    "        seed_iteration += 1\n",
    "        np.random.seed(seed_iteration)\n",
    "\n",
    "        #make 3 random images with rectangles\n",
    "        top_lefts = [{\"top\": np.random.randint(1, img_size-1), \"left\": np.random.randint(1, img_size-1)} for _ in range(3)]\n",
    "        bottom_rights = [{\"bottom\": np.random.randint(d[\"top\"] + 1, img_size), \"right\": np.random.randint(d[\"left\"] + 1, img_size)} for d in top_lefts]\n",
    "        coords = [top_left | bottom_right for top_left, bottom_right in zip(top_lefts, bottom_rights)]\n",
    "        trio = [create_image_with_white_rectangle(coord, img_size) for coord in coords]\n",
    "   \n",
    "        #sample parameters for analogies\n",
    "        mirror_horizontal = np.random.choice([True, False])\n",
    "        rotation_degree = np.random.choice([90, 180, 270])\n",
    "        grow_left = np.random.choice([0,0,1,2])\n",
    "        grow_right = np.random.choice([0,0,1,2])\n",
    "        grow_top = np.random.choice([0,0,1,2])\n",
    "        grow_bottom = np.random.choice([0,0,1,2])\n",
    "        move_vertical = np.random.choice([0,1,2])\n",
    "        move_horizontal = np.random.choice([0,1,2])\n",
    "        furthest_edge = np.random.choice([True, False])\n",
    "        furthest_corner = np.random.choice([True, False])\n",
    "        reverse_shadows = np.random.choice([True, False])\n",
    "\n",
    "        # Generate analogies\n",
    "        resizes = [resize_rectangle(img, coord, grow_top, grow_bottom, grow_left, grow_right) for img, coord in zip(trio, coords)]\n",
    "        moves = [move_rectangle(img, move_horizontal, move_vertical)  for img in trio]\n",
    "        rotations = [rotate_image(img, rotation_degree) for img in trio]\n",
    "        inversions = [invert_colors(img)  for img in trio]\n",
    "        mirrors = [mirror_image(img, horizontal=mirror_horizontal) for img in trio]\n",
    "        corner_cells = [paint_corner(img, furthest_corner) for img in trio]\n",
    "        edges = [paint_edge(img, coord, furthest_edge) for img, coord in zip(trio, coords)]\n",
    "        stretches = [stretch_rectangle(img, coord) for img, coord in zip(trio, coords)]\n",
    "        shadows = [draw_shadows(img, coord, reverse_shadows)  for img, coord in zip(trio, coords)]\n",
    "        \n",
    "        #check whether images violate rules (original three include duplicates; initial transformations left the canvas)\n",
    "        if np.array_equal(trio[0], trio[1]) or np.array_equal(trio[0], trio[2]) or np.array_equal(trio[1], trio[2]):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(moves[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(resizes[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        else:\n",
    "            invalid_img = False\n",
    "    \n",
    "    transformed_trios = [resizes, moves, rotations, inversions, mirrors, corner_cells, edges, stretches, shadows]\n",
    "    data.append([np.stack([trio, transformed_trio]) for transformed_trio in transformed_trios])\n",
    "\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3% duplicated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this cell is for reformatting the df; one could e.g. slice off specific data here (e.g., for a test set with new analogies)\n",
    "long_data = data.reshape(data.shape[0]*data.shape[1], data.shape[2], data.shape[3], data.shape[4], data.shape[5])\n",
    "long_data = long_data.reshape(long_data.shape[0], long_data.shape[1] * long_data.shape[2], long_data.shape[3], long_data.shape[4])\n",
    "plot_double_trio(long_data[8]) #first 9 on first dim are same trio and all 9 transformations; then it starts over with second trio\n",
    "nonduplicates = np.unique(long_data, axis=0) #get rid of duplicated tasks\n",
    "print(f\"{np.round(100*(1 - nonduplicates.shape[0] / long_data.shape[0]),1)}% double trios were duplicated\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nonduplicates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nonduplicates, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([892890, 5, 10, 10])\n",
      "y_train shape: torch.Size([892890, 10, 10])\n",
      "x_test shape: torch.Size([4487, 5, 10, 10])\n",
      "y_test shape: torch.Size([4487, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into input (x) and output (y)\n",
    "x_data = nonduplicates[:, :-1, :, :] / 255 # All but the last channel\n",
    "y_data = nonduplicates[:, -1, :, :] / 255  # Only the last channel\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_data = torch.from_numpy(x_data).float()\n",
    "y_data = torch.from_numpy(y_data).float()\n",
    "\n",
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.005, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting tensors\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.2509\n",
      "Test Loss: 0.2401\n",
      "Epoch [2/500], Loss: 0.2390\n",
      "Test Loss: 0.1929\n",
      "Epoch [3/500], Loss: 0.1909\n",
      "Test Loss: 0.1507\n",
      "Epoch [4/500], Loss: 0.1482\n",
      "Test Loss: 0.1393\n",
      "Epoch [5/500], Loss: 0.1376\n",
      "Test Loss: 0.1340\n",
      "Epoch [6/500], Loss: 0.1325\n",
      "Test Loss: 0.1263\n",
      "Epoch [7/500], Loss: 0.1254\n",
      "Test Loss: 0.1212\n",
      "Epoch [8/500], Loss: 0.1206\n",
      "Test Loss: 0.1202\n",
      "Epoch [9/500], Loss: 0.1189\n",
      "Test Loss: 0.1156\n",
      "Epoch [10/500], Loss: 0.1152\n",
      "Test Loss: 0.1180\n",
      "Epoch [11/500], Loss: 0.1179\n",
      "Test Loss: 0.1145\n",
      "Epoch [12/500], Loss: 0.1138\n",
      "Test Loss: 0.1141\n",
      "Epoch [13/500], Loss: 0.1135\n",
      "Test Loss: 0.1121\n",
      "Epoch [14/500], Loss: 0.1119\n",
      "Test Loss: 0.1123\n",
      "Epoch [15/500], Loss: 0.1123\n",
      "Test Loss: 0.1120\n",
      "Epoch [16/500], Loss: 0.1119\n",
      "Test Loss: 0.1115\n",
      "Epoch [17/500], Loss: 0.1112\n",
      "Test Loss: 0.1093\n",
      "Epoch [18/500], Loss: 0.1089\n",
      "Test Loss: 0.1082\n",
      "Epoch [19/500], Loss: 0.1074\n",
      "Test Loss: 0.1070\n",
      "Epoch [20/500], Loss: 0.1059\n",
      "Test Loss: 0.1050\n",
      "Epoch [21/500], Loss: 0.1038\n",
      "Test Loss: 0.1030\n",
      "Epoch [22/500], Loss: 0.1016\n",
      "Test Loss: 0.1007\n",
      "Epoch [23/500], Loss: 0.0994\n",
      "Test Loss: 0.0988\n",
      "Epoch [24/500], Loss: 0.0974\n",
      "Test Loss: 0.0969\n",
      "Epoch [25/500], Loss: 0.0957\n",
      "Test Loss: 0.0953\n",
      "Epoch [26/500], Loss: 0.0941\n",
      "Test Loss: 0.0932\n",
      "Epoch [27/500], Loss: 0.0920\n",
      "Test Loss: 0.0920\n",
      "Epoch [28/500], Loss: 0.0908\n",
      "Test Loss: 0.0909\n",
      "Epoch [29/500], Loss: 0.0897\n",
      "Test Loss: 0.0899\n",
      "Epoch [30/500], Loss: 0.0885\n",
      "Test Loss: 0.0891\n",
      "Epoch [31/500], Loss: 0.0876\n",
      "Test Loss: 0.0886\n",
      "Epoch [32/500], Loss: 0.0872\n",
      "Test Loss: 0.0884\n",
      "Epoch [33/500], Loss: 0.0871\n",
      "Test Loss: 0.0884\n",
      "Epoch [34/500], Loss: 0.0871\n",
      "Test Loss: 0.0879\n",
      "Epoch [35/500], Loss: 0.0865\n",
      "Test Loss: 0.0863\n",
      "Epoch [36/500], Loss: 0.0848\n",
      "Test Loss: 0.0863\n",
      "Epoch [37/500], Loss: 0.0849\n",
      "Test Loss: 0.0863\n",
      "Epoch [38/500], Loss: 0.0848\n",
      "Test Loss: 0.0849\n",
      "Epoch [39/500], Loss: 0.0834\n",
      "Test Loss: 0.0852\n",
      "Epoch [40/500], Loss: 0.0837\n",
      "Test Loss: 0.0842\n",
      "Epoch [41/500], Loss: 0.0827\n",
      "Test Loss: 0.0841\n",
      "Epoch [42/500], Loss: 0.0826\n",
      "Test Loss: 0.0837\n",
      "Epoch [43/500], Loss: 0.0822\n",
      "Test Loss: 0.0832\n",
      "Epoch [44/500], Loss: 0.0817\n",
      "Test Loss: 0.0830\n",
      "Epoch [45/500], Loss: 0.0815\n",
      "Test Loss: 0.0827\n",
      "Epoch [46/500], Loss: 0.0811\n",
      "Test Loss: 0.0824\n",
      "Epoch [47/500], Loss: 0.0809\n",
      "Test Loss: 0.0821\n",
      "Epoch [48/500], Loss: 0.0806\n",
      "Test Loss: 0.0817\n",
      "Epoch [49/500], Loss: 0.0801\n",
      "Test Loss: 0.0815\n",
      "Epoch [50/500], Loss: 0.0800\n",
      "Test Loss: 0.0813\n",
      "Epoch [51/500], Loss: 0.0797\n",
      "Test Loss: 0.0808\n",
      "Epoch [52/500], Loss: 0.0792\n",
      "Test Loss: 0.0807\n",
      "Epoch [53/500], Loss: 0.0791\n",
      "Test Loss: 0.0804\n",
      "Epoch [54/500], Loss: 0.0788\n",
      "Test Loss: 0.0801\n",
      "Epoch [55/500], Loss: 0.0784\n",
      "Test Loss: 0.0800\n",
      "Epoch [56/500], Loss: 0.0783\n",
      "Test Loss: 0.0797\n",
      "Epoch [57/500], Loss: 0.0780\n",
      "Test Loss: 0.0794\n",
      "Epoch [58/500], Loss: 0.0776\n",
      "Test Loss: 0.0792\n",
      "Epoch [59/500], Loss: 0.0774\n",
      "Test Loss: 0.0790\n",
      "Epoch [60/500], Loss: 0.0772\n",
      "Test Loss: 0.0787\n",
      "Epoch [61/500], Loss: 0.0768\n",
      "Test Loss: 0.0783\n",
      "Epoch [62/500], Loss: 0.0764\n",
      "Test Loss: 0.0781\n",
      "Epoch [63/500], Loss: 0.0761\n",
      "Test Loss: 0.0779\n",
      "Epoch [64/500], Loss: 0.0759\n",
      "Test Loss: 0.0777\n",
      "Epoch [65/500], Loss: 0.0757\n",
      "Test Loss: 0.0776\n",
      "Epoch [66/500], Loss: 0.0755\n",
      "Test Loss: 0.0772\n",
      "Epoch [67/500], Loss: 0.0753\n",
      "Test Loss: 0.0767\n",
      "Epoch [68/500], Loss: 0.0747\n",
      "Test Loss: 0.0762\n",
      "Epoch [69/500], Loss: 0.0742\n",
      "Test Loss: 0.0759\n",
      "Epoch [70/500], Loss: 0.0740\n",
      "Test Loss: 0.0758\n",
      "Epoch [71/500], Loss: 0.0738\n",
      "Test Loss: 0.0756\n",
      "Epoch [72/500], Loss: 0.0737\n",
      "Test Loss: 0.0755\n",
      "Epoch [73/500], Loss: 0.0735\n",
      "Test Loss: 0.0753\n",
      "Epoch [74/500], Loss: 0.0734\n",
      "Test Loss: 0.0746\n",
      "Epoch [75/500], Loss: 0.0727\n",
      "Test Loss: 0.0738\n",
      "Epoch [76/500], Loss: 0.0719\n",
      "Test Loss: 0.0733\n",
      "Epoch [77/500], Loss: 0.0714\n",
      "Test Loss: 0.0730\n",
      "Epoch [78/500], Loss: 0.0711\n",
      "Test Loss: 0.0729\n",
      "Epoch [79/500], Loss: 0.0711\n",
      "Test Loss: 0.0726\n",
      "Epoch [80/500], Loss: 0.0708\n",
      "Test Loss: 0.0726\n",
      "Epoch [81/500], Loss: 0.0708\n",
      "Test Loss: 0.0716\n",
      "Epoch [82/500], Loss: 0.0698\n",
      "Test Loss: 0.0708\n",
      "Epoch [83/500], Loss: 0.0690\n",
      "Test Loss: 0.0709\n",
      "Epoch [84/500], Loss: 0.0691\n",
      "Test Loss: 0.0712\n",
      "Epoch [85/500], Loss: 0.0694\n",
      "Test Loss: 0.0717\n",
      "Epoch [86/500], Loss: 0.0700\n",
      "Test Loss: 0.0693\n",
      "Epoch [87/500], Loss: 0.0676\n",
      "Test Loss: 0.0709\n",
      "Epoch [88/500], Loss: 0.0691\n",
      "Test Loss: 0.0703\n",
      "Epoch [89/500], Loss: 0.0687\n",
      "Test Loss: 0.0696\n",
      "Epoch [90/500], Loss: 0.0680\n",
      "Test Loss: 0.0695\n",
      "Epoch [91/500], Loss: 0.0679\n",
      "Test Loss: 0.0689\n",
      "Epoch [92/500], Loss: 0.0673\n",
      "Test Loss: 0.0685\n",
      "Epoch [93/500], Loss: 0.0667\n",
      "Test Loss: 0.0683\n",
      "Epoch [94/500], Loss: 0.0666\n",
      "Test Loss: 0.0683\n",
      "Epoch [95/500], Loss: 0.0667\n",
      "Test Loss: 0.0675\n",
      "Epoch [96/500], Loss: 0.0658\n",
      "Test Loss: 0.0680\n",
      "Epoch [97/500], Loss: 0.0662\n",
      "Test Loss: 0.0669\n",
      "Epoch [98/500], Loss: 0.0651\n",
      "Test Loss: 0.0667\n",
      "Epoch [99/500], Loss: 0.0650\n",
      "Test Loss: 0.0663\n",
      "Epoch [100/500], Loss: 0.0646\n",
      "Test Loss: 0.0661\n",
      "Epoch [101/500], Loss: 0.0643\n",
      "Test Loss: 0.0658\n",
      "Epoch [102/500], Loss: 0.0640\n",
      "Test Loss: 0.0655\n",
      "Epoch [103/500], Loss: 0.0638\n",
      "Test Loss: 0.0651\n",
      "Epoch [104/500], Loss: 0.0633\n",
      "Test Loss: 0.0650\n",
      "Epoch [105/500], Loss: 0.0632\n",
      "Test Loss: 0.0645\n",
      "Epoch [106/500], Loss: 0.0627\n",
      "Test Loss: 0.0644\n",
      "Epoch [107/500], Loss: 0.0626\n",
      "Test Loss: 0.0640\n",
      "Epoch [108/500], Loss: 0.0623\n",
      "Test Loss: 0.0638\n",
      "Epoch [109/500], Loss: 0.0621\n",
      "Test Loss: 0.0635\n",
      "Epoch [110/500], Loss: 0.0617\n",
      "Test Loss: 0.0631\n",
      "Epoch [111/500], Loss: 0.0614\n",
      "Test Loss: 0.0629\n",
      "Epoch [112/500], Loss: 0.0612\n",
      "Test Loss: 0.0625\n",
      "Epoch [113/500], Loss: 0.0608\n",
      "Test Loss: 0.0623\n",
      "Epoch [114/500], Loss: 0.0606\n",
      "Test Loss: 0.0619\n",
      "Epoch [115/500], Loss: 0.0602\n",
      "Test Loss: 0.0616\n",
      "Epoch [116/500], Loss: 0.0600\n",
      "Test Loss: 0.0613\n",
      "Epoch [117/500], Loss: 0.0596\n",
      "Test Loss: 0.0610\n",
      "Epoch [118/500], Loss: 0.0593\n",
      "Test Loss: 0.0606\n",
      "Epoch [119/500], Loss: 0.0590\n",
      "Test Loss: 0.0605\n",
      "Epoch [120/500], Loss: 0.0589\n",
      "Test Loss: 0.0607\n",
      "Epoch [121/500], Loss: 0.0591\n",
      "Test Loss: 0.0620\n",
      "Epoch [122/500], Loss: 0.0605\n",
      "Test Loss: 0.0619\n",
      "Epoch [123/500], Loss: 0.0604\n",
      "Test Loss: 0.0616\n",
      "Epoch [124/500], Loss: 0.0599\n",
      "Test Loss: 0.0593\n",
      "Epoch [125/500], Loss: 0.0577\n",
      "Test Loss: 0.0598\n",
      "Epoch [126/500], Loss: 0.0583\n",
      "Test Loss: 0.0605\n",
      "Epoch [127/500], Loss: 0.0590\n",
      "Test Loss: 0.0583\n",
      "Epoch [128/500], Loss: 0.0569\n",
      "Test Loss: 0.0600\n",
      "Epoch [129/500], Loss: 0.0584\n",
      "Test Loss: 0.0604\n",
      "Epoch [130/500], Loss: 0.0589\n",
      "Test Loss: 0.0584\n",
      "Epoch [131/500], Loss: 0.0569\n",
      "Test Loss: 0.0601\n",
      "Epoch [132/500], Loss: 0.0585\n",
      "Test Loss: 0.0577\n",
      "Epoch [133/500], Loss: 0.0562\n",
      "Test Loss: 0.0582\n",
      "Epoch [134/500], Loss: 0.0568\n",
      "Test Loss: 0.0569\n",
      "Epoch [135/500], Loss: 0.0555\n",
      "Test Loss: 0.0569\n",
      "Epoch [136/500], Loss: 0.0556\n",
      "Test Loss: 0.0566\n",
      "Epoch [137/500], Loss: 0.0553\n",
      "Test Loss: 0.0559\n",
      "Epoch [138/500], Loss: 0.0547\n",
      "Test Loss: 0.0559\n",
      "Epoch [139/500], Loss: 0.0546\n",
      "Test Loss: 0.0550\n",
      "Epoch [140/500], Loss: 0.0538\n",
      "Test Loss: 0.0551\n",
      "Epoch [141/500], Loss: 0.0539\n",
      "Test Loss: 0.0545\n",
      "Epoch [142/500], Loss: 0.0532\n",
      "Test Loss: 0.0545\n",
      "Epoch [143/500], Loss: 0.0532\n",
      "Test Loss: 0.0540\n",
      "Epoch [144/500], Loss: 0.0527\n",
      "Test Loss: 0.0535\n",
      "Epoch [145/500], Loss: 0.0524\n",
      "Test Loss: 0.0534\n",
      "Epoch [146/500], Loss: 0.0522\n",
      "Test Loss: 0.0531\n",
      "Epoch [147/500], Loss: 0.0518\n",
      "Test Loss: 0.0527\n",
      "Epoch [148/500], Loss: 0.0515\n",
      "Test Loss: 0.0525\n",
      "Epoch [149/500], Loss: 0.0513\n",
      "Test Loss: 0.0522\n",
      "Epoch [150/500], Loss: 0.0510\n",
      "Test Loss: 0.0521\n",
      "Epoch [151/500], Loss: 0.0508\n",
      "Test Loss: 0.0516\n",
      "Epoch [152/500], Loss: 0.0504\n",
      "Test Loss: 0.0515\n",
      "Epoch [153/500], Loss: 0.0503\n",
      "Test Loss: 0.0512\n",
      "Epoch [154/500], Loss: 0.0500\n",
      "Test Loss: 0.0509\n",
      "Epoch [155/500], Loss: 0.0497\n",
      "Test Loss: 0.0508\n",
      "Epoch [156/500], Loss: 0.0495\n",
      "Test Loss: 0.0506\n",
      "Epoch [157/500], Loss: 0.0493\n",
      "Test Loss: 0.0503\n",
      "Epoch [158/500], Loss: 0.0490\n",
      "Test Loss: 0.0508\n",
      "Epoch [159/500], Loss: 0.0496\n",
      "Test Loss: 0.0511\n",
      "Epoch [160/500], Loss: 0.0498\n",
      "Test Loss: 0.0517\n",
      "Epoch [161/500], Loss: 0.0506\n",
      "Test Loss: 0.0524\n",
      "Epoch [162/500], Loss: 0.0511\n",
      "Test Loss: 0.0503\n",
      "Epoch [163/500], Loss: 0.0492\n",
      "Test Loss: 0.0505\n",
      "Epoch [164/500], Loss: 0.0494\n",
      "Test Loss: 0.0514\n",
      "Epoch [165/500], Loss: 0.0501\n",
      "Test Loss: 0.0495\n",
      "Epoch [166/500], Loss: 0.0483\n",
      "Test Loss: 0.0504\n",
      "Epoch [167/500], Loss: 0.0492\n",
      "Test Loss: 0.0502\n",
      "Epoch [168/500], Loss: 0.0489\n",
      "Test Loss: 0.0493\n",
      "Epoch [169/500], Loss: 0.0480\n",
      "Test Loss: 0.0495\n",
      "Epoch [170/500], Loss: 0.0484\n",
      "Test Loss: 0.0483\n",
      "Epoch [171/500], Loss: 0.0471\n",
      "Test Loss: 0.0487\n",
      "Epoch [172/500], Loss: 0.0476\n",
      "Test Loss: 0.0478\n",
      "Epoch [173/500], Loss: 0.0466\n",
      "Test Loss: 0.0479\n",
      "Epoch [174/500], Loss: 0.0467\n",
      "Test Loss: 0.0475\n",
      "Epoch [175/500], Loss: 0.0464\n",
      "Test Loss: 0.0472\n",
      "Epoch [176/500], Loss: 0.0460\n",
      "Test Loss: 0.0470\n",
      "Epoch [177/500], Loss: 0.0458\n",
      "Test Loss: 0.0465\n",
      "Epoch [178/500], Loss: 0.0454\n",
      "Test Loss: 0.0464\n",
      "Epoch [179/500], Loss: 0.0453\n",
      "Test Loss: 0.0460\n",
      "Epoch [180/500], Loss: 0.0448\n",
      "Test Loss: 0.0460\n",
      "Epoch [181/500], Loss: 0.0448\n",
      "Test Loss: 0.0455\n",
      "Epoch [182/500], Loss: 0.0444\n",
      "Test Loss: 0.0453\n",
      "Epoch [183/500], Loss: 0.0442\n",
      "Test Loss: 0.0451\n",
      "Epoch [184/500], Loss: 0.0440\n",
      "Test Loss: 0.0448\n",
      "Epoch [185/500], Loss: 0.0438\n",
      "Test Loss: 0.0445\n",
      "Epoch [186/500], Loss: 0.0435\n",
      "Test Loss: 0.0443\n",
      "Epoch [187/500], Loss: 0.0433\n",
      "Test Loss: 0.0441\n",
      "Epoch [188/500], Loss: 0.0431\n",
      "Test Loss: 0.0439\n",
      "Epoch [189/500], Loss: 0.0429\n",
      "Test Loss: 0.0435\n",
      "Epoch [190/500], Loss: 0.0426\n",
      "Test Loss: 0.0434\n",
      "Epoch [191/500], Loss: 0.0424\n",
      "Test Loss: 0.0431\n",
      "Epoch [192/500], Loss: 0.0421\n",
      "Test Loss: 0.0429\n",
      "Epoch [193/500], Loss: 0.0419\n",
      "Test Loss: 0.0427\n",
      "Epoch [194/500], Loss: 0.0417\n",
      "Test Loss: 0.0425\n",
      "Epoch [195/500], Loss: 0.0415\n",
      "Test Loss: 0.0422\n",
      "Epoch [196/500], Loss: 0.0412\n",
      "Test Loss: 0.0420\n",
      "Epoch [197/500], Loss: 0.0410\n",
      "Test Loss: 0.0418\n",
      "Epoch [198/500], Loss: 0.0408\n",
      "Test Loss: 0.0416\n",
      "Epoch [199/500], Loss: 0.0406\n",
      "Test Loss: 0.0414\n",
      "Epoch [200/500], Loss: 0.0404\n",
      "Test Loss: 0.0411\n",
      "Epoch [201/500], Loss: 0.0402\n",
      "Test Loss: 0.0410\n",
      "Epoch [202/500], Loss: 0.0400\n",
      "Test Loss: 0.0409\n",
      "Epoch [203/500], Loss: 0.0399\n",
      "Test Loss: 0.0408\n",
      "Epoch [204/500], Loss: 0.0398\n",
      "Test Loss: 0.0409\n",
      "Epoch [205/500], Loss: 0.0399\n",
      "Test Loss: 0.0411\n",
      "Epoch [206/500], Loss: 0.0401\n",
      "Test Loss: 0.0414\n",
      "Epoch [207/500], Loss: 0.0404\n",
      "Test Loss: 0.0408\n",
      "Epoch [208/500], Loss: 0.0398\n",
      "Test Loss: 0.0399\n",
      "Epoch [209/500], Loss: 0.0390\n",
      "Test Loss: 0.0393\n",
      "Epoch [210/500], Loss: 0.0384\n",
      "Test Loss: 0.0394\n",
      "Epoch [211/500], Loss: 0.0384\n",
      "Test Loss: 0.0397\n",
      "Epoch [212/500], Loss: 0.0387\n",
      "Test Loss: 0.0395\n",
      "Epoch [213/500], Loss: 0.0385\n",
      "Test Loss: 0.0390\n",
      "Epoch [214/500], Loss: 0.0380\n",
      "Test Loss: 0.0383\n",
      "Epoch [215/500], Loss: 0.0374\n",
      "Test Loss: 0.0384\n",
      "Epoch [216/500], Loss: 0.0374\n",
      "Test Loss: 0.0386\n",
      "Epoch [217/500], Loss: 0.0376\n",
      "Test Loss: 0.0384\n",
      "Epoch [218/500], Loss: 0.0373\n",
      "Test Loss: 0.0378\n",
      "Epoch [219/500], Loss: 0.0368\n",
      "Test Loss: 0.0374\n",
      "Epoch [220/500], Loss: 0.0364\n",
      "Test Loss: 0.0373\n",
      "Epoch [221/500], Loss: 0.0363\n",
      "Test Loss: 0.0374\n",
      "Epoch [222/500], Loss: 0.0364\n",
      "Test Loss: 0.0374\n",
      "Epoch [223/500], Loss: 0.0364\n",
      "Test Loss: 0.0371\n",
      "Epoch [224/500], Loss: 0.0362\n",
      "Test Loss: 0.0367\n",
      "Epoch [225/500], Loss: 0.0358\n",
      "Test Loss: 0.0366\n",
      "Epoch [226/500], Loss: 0.0356\n",
      "Test Loss: 0.0364\n",
      "Epoch [227/500], Loss: 0.0355\n",
      "Test Loss: 0.0368\n",
      "Epoch [228/500], Loss: 0.0358\n",
      "Test Loss: 0.0371\n",
      "Epoch [229/500], Loss: 0.0362\n",
      "Test Loss: 0.0370\n",
      "Epoch [230/500], Loss: 0.0361\n",
      "Test Loss: 0.0360\n",
      "Epoch [231/500], Loss: 0.0352\n",
      "Test Loss: 0.0352\n",
      "Epoch [232/500], Loss: 0.0344\n",
      "Test Loss: 0.0356\n",
      "Epoch [233/500], Loss: 0.0347\n",
      "Test Loss: 0.0359\n",
      "Epoch [234/500], Loss: 0.0351\n",
      "Test Loss: 0.0353\n",
      "Epoch [235/500], Loss: 0.0344\n",
      "Test Loss: 0.0345\n",
      "Epoch [236/500], Loss: 0.0337\n",
      "Test Loss: 0.0345\n",
      "Epoch [237/500], Loss: 0.0336\n",
      "Test Loss: 0.0349\n",
      "Epoch [238/500], Loss: 0.0340\n",
      "Test Loss: 0.0345\n",
      "Epoch [239/500], Loss: 0.0336\n",
      "Test Loss: 0.0337\n",
      "Epoch [240/500], Loss: 0.0329\n",
      "Test Loss: 0.0339\n",
      "Epoch [241/500], Loss: 0.0330\n",
      "Test Loss: 0.0341\n",
      "Epoch [242/500], Loss: 0.0332\n",
      "Test Loss: 0.0335\n",
      "Epoch [243/500], Loss: 0.0327\n",
      "Test Loss: 0.0331\n",
      "Epoch [244/500], Loss: 0.0322\n",
      "Test Loss: 0.0332\n",
      "Epoch [245/500], Loss: 0.0323\n",
      "Test Loss: 0.0331\n",
      "Epoch [246/500], Loss: 0.0322\n",
      "Test Loss: 0.0327\n",
      "Epoch [247/500], Loss: 0.0319\n",
      "Test Loss: 0.0325\n",
      "Epoch [248/500], Loss: 0.0316\n",
      "Test Loss: 0.0325\n",
      "Epoch [249/500], Loss: 0.0316\n",
      "Test Loss: 0.0324\n",
      "Epoch [250/500], Loss: 0.0315\n",
      "Test Loss: 0.0321\n",
      "Epoch [251/500], Loss: 0.0313\n",
      "Test Loss: 0.0323\n",
      "Epoch [252/500], Loss: 0.0314\n",
      "Test Loss: 0.0327\n",
      "Epoch [253/500], Loss: 0.0319\n",
      "Test Loss: 0.0337\n",
      "Epoch [254/500], Loss: 0.0328\n",
      "Test Loss: 0.0350\n",
      "Epoch [255/500], Loss: 0.0341\n",
      "Test Loss: 0.0358\n",
      "Epoch [256/500], Loss: 0.0348\n",
      "Test Loss: 0.0321\n",
      "Epoch [257/500], Loss: 0.0312\n",
      "Test Loss: 0.0324\n",
      "Epoch [258/500], Loss: 0.0316\n",
      "Test Loss: 0.0343\n",
      "Epoch [259/500], Loss: 0.0333\n",
      "Test Loss: 0.0320\n",
      "Epoch [260/500], Loss: 0.0312\n",
      "Test Loss: 0.0329\n",
      "Epoch [261/500], Loss: 0.0321\n",
      "Test Loss: 0.0329\n",
      "Epoch [262/500], Loss: 0.0320\n",
      "Test Loss: 0.0326\n",
      "Epoch [263/500], Loss: 0.0319\n",
      "Test Loss: 0.0322\n",
      "Epoch [264/500], Loss: 0.0314\n",
      "Test Loss: 0.0317\n",
      "Epoch [265/500], Loss: 0.0308\n",
      "Test Loss: 0.0318\n",
      "Epoch [266/500], Loss: 0.0310\n",
      "Test Loss: 0.0307\n",
      "Epoch [267/500], Loss: 0.0300\n",
      "Test Loss: 0.0311\n",
      "Epoch [268/500], Loss: 0.0304\n",
      "Test Loss: 0.0307\n",
      "Epoch [269/500], Loss: 0.0298\n",
      "Test Loss: 0.0307\n",
      "Epoch [270/500], Loss: 0.0298\n",
      "Test Loss: 0.0304\n",
      "Epoch [271/500], Loss: 0.0296\n",
      "Test Loss: 0.0302\n",
      "Epoch [272/500], Loss: 0.0294\n",
      "Test Loss: 0.0302\n",
      "Epoch [273/500], Loss: 0.0293\n",
      "Test Loss: 0.0298\n",
      "Epoch [274/500], Loss: 0.0289\n",
      "Test Loss: 0.0298\n",
      "Epoch [275/500], Loss: 0.0290\n",
      "Test Loss: 0.0294\n",
      "Epoch [276/500], Loss: 0.0286\n",
      "Test Loss: 0.0295\n",
      "Epoch [277/500], Loss: 0.0287\n",
      "Test Loss: 0.0291\n",
      "Epoch [278/500], Loss: 0.0283\n",
      "Test Loss: 0.0291\n",
      "Epoch [279/500], Loss: 0.0283\n",
      "Test Loss: 0.0290\n",
      "Epoch [280/500], Loss: 0.0282\n",
      "Test Loss: 0.0287\n",
      "Epoch [281/500], Loss: 0.0279\n",
      "Test Loss: 0.0288\n",
      "Epoch [282/500], Loss: 0.0280\n",
      "Test Loss: 0.0284\n",
      "Epoch [283/500], Loss: 0.0277\n",
      "Test Loss: 0.0285\n",
      "Epoch [284/500], Loss: 0.0277\n",
      "Test Loss: 0.0282\n",
      "Epoch [285/500], Loss: 0.0275\n",
      "Test Loss: 0.0281\n",
      "Epoch [286/500], Loss: 0.0274\n",
      "Test Loss: 0.0281\n",
      "Epoch [287/500], Loss: 0.0273\n",
      "Test Loss: 0.0279\n",
      "Epoch [288/500], Loss: 0.0272\n",
      "Test Loss: 0.0278\n",
      "Epoch [289/500], Loss: 0.0271\n",
      "Test Loss: 0.0277\n",
      "Epoch [290/500], Loss: 0.0270\n",
      "Test Loss: 0.0275\n",
      "Epoch [291/500], Loss: 0.0268\n",
      "Test Loss: 0.0275\n",
      "Epoch [292/500], Loss: 0.0268\n",
      "Test Loss: 0.0274\n",
      "Epoch [293/500], Loss: 0.0266\n",
      "Test Loss: 0.0273\n",
      "Epoch [294/500], Loss: 0.0265\n",
      "Test Loss: 0.0272\n",
      "Epoch [295/500], Loss: 0.0265\n",
      "Test Loss: 0.0270\n",
      "Epoch [296/500], Loss: 0.0263\n",
      "Test Loss: 0.0270\n",
      "Epoch [297/500], Loss: 0.0263\n",
      "Test Loss: 0.0269\n",
      "Epoch [298/500], Loss: 0.0262\n",
      "Test Loss: 0.0269\n",
      "Epoch [299/500], Loss: 0.0262\n",
      "Test Loss: 0.0269\n",
      "Epoch [300/500], Loss: 0.0262\n",
      "Test Loss: 0.0271\n",
      "Epoch [301/500], Loss: 0.0264\n",
      "Test Loss: 0.0273\n",
      "Epoch [302/500], Loss: 0.0266\n",
      "Test Loss: 0.0275\n",
      "Epoch [303/500], Loss: 0.0269\n",
      "Test Loss: 0.0274\n",
      "Epoch [304/500], Loss: 0.0267\n",
      "Test Loss: 0.0269\n",
      "Epoch [305/500], Loss: 0.0262\n",
      "Test Loss: 0.0264\n",
      "Epoch [306/500], Loss: 0.0257\n",
      "Test Loss: 0.0264\n",
      "Epoch [307/500], Loss: 0.0258\n",
      "Test Loss: 0.0265\n",
      "Epoch [308/500], Loss: 0.0259\n",
      "Test Loss: 0.0264\n",
      "Epoch [309/500], Loss: 0.0257\n",
      "Test Loss: 0.0260\n",
      "Epoch [310/500], Loss: 0.0254\n",
      "Test Loss: 0.0259\n",
      "Epoch [311/500], Loss: 0.0253\n",
      "Test Loss: 0.0262\n",
      "Epoch [312/500], Loss: 0.0255\n",
      "Test Loss: 0.0261\n",
      "Epoch [313/500], Loss: 0.0255\n",
      "Test Loss: 0.0257\n",
      "Epoch [314/500], Loss: 0.0251\n",
      "Test Loss: 0.0254\n",
      "Epoch [315/500], Loss: 0.0248\n",
      "Test Loss: 0.0254\n",
      "Epoch [316/500], Loss: 0.0248\n",
      "Test Loss: 0.0256\n",
      "Epoch [317/500], Loss: 0.0250\n",
      "Test Loss: 0.0255\n",
      "Epoch [318/500], Loss: 0.0248\n",
      "Test Loss: 0.0253\n",
      "Epoch [319/500], Loss: 0.0246\n",
      "Test Loss: 0.0251\n",
      "Epoch [320/500], Loss: 0.0244\n",
      "Test Loss: 0.0252\n",
      "Epoch [321/500], Loss: 0.0245\n",
      "Test Loss: 0.0252\n",
      "Epoch [322/500], Loss: 0.0245\n",
      "Test Loss: 0.0251\n",
      "Epoch [323/500], Loss: 0.0245\n",
      "Test Loss: 0.0250\n",
      "Epoch [324/500], Loss: 0.0243\n",
      "Test Loss: 0.0249\n",
      "Epoch [325/500], Loss: 0.0242\n",
      "Test Loss: 0.0251\n",
      "Epoch [326/500], Loss: 0.0244\n",
      "Test Loss: 0.0256\n",
      "Epoch [327/500], Loss: 0.0249\n",
      "Test Loss: 0.0265\n",
      "Epoch [328/500], Loss: 0.0257\n",
      "Test Loss: 0.0276\n",
      "Epoch [329/500], Loss: 0.0268\n",
      "Test Loss: 0.0267\n",
      "Epoch [330/500], Loss: 0.0259\n",
      "Test Loss: 0.0254\n",
      "Epoch [331/500], Loss: 0.0248\n",
      "Test Loss: 0.0248\n",
      "Epoch [332/500], Loss: 0.0241\n",
      "Test Loss: 0.0254\n",
      "Epoch [333/500], Loss: 0.0247\n",
      "Test Loss: 0.0259\n",
      "Epoch [334/500], Loss: 0.0253\n",
      "Test Loss: 0.0250\n",
      "Epoch [335/500], Loss: 0.0243\n",
      "Test Loss: 0.0244\n",
      "Epoch [336/500], Loss: 0.0237\n",
      "Test Loss: 0.0252\n",
      "Epoch [337/500], Loss: 0.0245\n",
      "Test Loss: 0.0251\n",
      "Epoch [338/500], Loss: 0.0244\n",
      "Test Loss: 0.0242\n",
      "Epoch [339/500], Loss: 0.0235\n",
      "Test Loss: 0.0244\n",
      "Epoch [340/500], Loss: 0.0237\n",
      "Test Loss: 0.0247\n",
      "Epoch [341/500], Loss: 0.0240\n",
      "Test Loss: 0.0242\n",
      "Epoch [342/500], Loss: 0.0235\n",
      "Test Loss: 0.0241\n",
      "Epoch [343/500], Loss: 0.0234\n",
      "Test Loss: 0.0241\n",
      "Epoch [344/500], Loss: 0.0234\n",
      "Test Loss: 0.0240\n",
      "Epoch [345/500], Loss: 0.0233\n",
      "Test Loss: 0.0238\n",
      "Epoch [346/500], Loss: 0.0232\n",
      "Test Loss: 0.0238\n",
      "Epoch [347/500], Loss: 0.0231\n",
      "Test Loss: 0.0237\n",
      "Epoch [348/500], Loss: 0.0230\n",
      "Test Loss: 0.0237\n",
      "Epoch [349/500], Loss: 0.0230\n",
      "Test Loss: 0.0234\n",
      "Epoch [350/500], Loss: 0.0228\n",
      "Test Loss: 0.0233\n",
      "Epoch [351/500], Loss: 0.0226\n",
      "Test Loss: 0.0235\n",
      "Epoch [352/500], Loss: 0.0228\n",
      "Test Loss: 0.0233\n",
      "Epoch [353/500], Loss: 0.0227\n",
      "Test Loss: 0.0231\n",
      "Epoch [354/500], Loss: 0.0224\n",
      "Test Loss: 0.0233\n",
      "Epoch [355/500], Loss: 0.0227\n",
      "Test Loss: 0.0231\n",
      "Epoch [356/500], Loss: 0.0225\n",
      "Test Loss: 0.0230\n",
      "Epoch [357/500], Loss: 0.0224\n",
      "Test Loss: 0.0231\n",
      "Epoch [358/500], Loss: 0.0224\n",
      "Test Loss: 0.0229\n",
      "Epoch [359/500], Loss: 0.0222\n",
      "Test Loss: 0.0229\n",
      "Epoch [360/500], Loss: 0.0222\n",
      "Test Loss: 0.0229\n",
      "Epoch [361/500], Loss: 0.0222\n",
      "Test Loss: 0.0228\n",
      "Epoch [362/500], Loss: 0.0221\n",
      "Test Loss: 0.0228\n",
      "Epoch [363/500], Loss: 0.0221\n",
      "Test Loss: 0.0228\n",
      "Epoch [364/500], Loss: 0.0222\n",
      "Test Loss: 0.0232\n",
      "Epoch [365/500], Loss: 0.0224\n",
      "Test Loss: 0.0233\n",
      "Epoch [366/500], Loss: 0.0226\n",
      "Test Loss: 0.0237\n",
      "Epoch [367/500], Loss: 0.0230\n",
      "Test Loss: 0.0235\n",
      "Epoch [368/500], Loss: 0.0229\n",
      "Test Loss: 0.0233\n",
      "Epoch [369/500], Loss: 0.0226\n",
      "Test Loss: 0.0226\n",
      "Epoch [370/500], Loss: 0.0219\n",
      "Test Loss: 0.0223\n",
      "Epoch [371/500], Loss: 0.0216\n",
      "Test Loss: 0.0226\n",
      "Epoch [372/500], Loss: 0.0219\n",
      "Test Loss: 0.0227\n",
      "Epoch [373/500], Loss: 0.0220\n",
      "Test Loss: 0.0226\n",
      "Epoch [374/500], Loss: 0.0218\n",
      "Test Loss: 0.0223\n",
      "Epoch [375/500], Loss: 0.0215\n",
      "Test Loss: 0.0222\n",
      "Epoch [376/500], Loss: 0.0215\n",
      "Test Loss: 0.0223\n",
      "Epoch [377/500], Loss: 0.0215\n",
      "Test Loss: 0.0221\n",
      "Epoch [378/500], Loss: 0.0215\n",
      "Test Loss: 0.0220\n",
      "Epoch [379/500], Loss: 0.0213\n",
      "Test Loss: 0.0218\n",
      "Epoch [380/500], Loss: 0.0212\n",
      "Test Loss: 0.0218\n",
      "Epoch [381/500], Loss: 0.0211\n",
      "Test Loss: 0.0218\n",
      "Epoch [382/500], Loss: 0.0211\n",
      "Test Loss: 0.0217\n",
      "Epoch [383/500], Loss: 0.0210\n",
      "Test Loss: 0.0216\n",
      "Epoch [384/500], Loss: 0.0209\n",
      "Test Loss: 0.0215\n",
      "Epoch [385/500], Loss: 0.0208\n",
      "Test Loss: 0.0215\n",
      "Epoch [386/500], Loss: 0.0208\n",
      "Test Loss: 0.0215\n",
      "Epoch [387/500], Loss: 0.0208\n",
      "Test Loss: 0.0214\n",
      "Epoch [388/500], Loss: 0.0207\n",
      "Test Loss: 0.0213\n",
      "Epoch [389/500], Loss: 0.0206\n",
      "Test Loss: 0.0212\n",
      "Epoch [390/500], Loss: 0.0205\n",
      "Test Loss: 0.0211\n",
      "Epoch [391/500], Loss: 0.0205\n",
      "Test Loss: 0.0212\n",
      "Epoch [392/500], Loss: 0.0205\n",
      "Test Loss: 0.0213\n",
      "Epoch [393/500], Loss: 0.0206\n",
      "Test Loss: 0.0213\n",
      "Epoch [394/500], Loss: 0.0206\n",
      "Test Loss: 0.0213\n",
      "Epoch [395/500], Loss: 0.0207\n",
      "Test Loss: 0.0215\n",
      "Epoch [396/500], Loss: 0.0208\n",
      "Test Loss: 0.0217\n",
      "Epoch [397/500], Loss: 0.0210\n",
      "Test Loss: 0.0217\n",
      "Epoch [398/500], Loss: 0.0210\n",
      "Test Loss: 0.0216\n",
      "Epoch [399/500], Loss: 0.0210\n",
      "Test Loss: 0.0211\n",
      "Epoch [400/500], Loss: 0.0205\n",
      "Test Loss: 0.0207\n",
      "Epoch [401/500], Loss: 0.0201\n",
      "Test Loss: 0.0205\n",
      "Epoch [402/500], Loss: 0.0199\n",
      "Test Loss: 0.0207\n",
      "Epoch [403/500], Loss: 0.0200\n",
      "Test Loss: 0.0209\n",
      "Epoch [404/500], Loss: 0.0203\n",
      "Test Loss: 0.0210\n",
      "Epoch [405/500], Loss: 0.0204\n",
      "Test Loss: 0.0209\n",
      "Epoch [406/500], Loss: 0.0202\n",
      "Test Loss: 0.0205\n",
      "Epoch [407/500], Loss: 0.0198\n",
      "Test Loss: 0.0203\n",
      "Epoch [408/500], Loss: 0.0197\n",
      "Test Loss: 0.0203\n",
      "Epoch [409/500], Loss: 0.0197\n",
      "Test Loss: 0.0205\n",
      "Epoch [410/500], Loss: 0.0198\n",
      "Test Loss: 0.0206\n",
      "Epoch [411/500], Loss: 0.0199\n",
      "Test Loss: 0.0205\n",
      "Epoch [412/500], Loss: 0.0199\n",
      "Test Loss: 0.0204\n",
      "Epoch [413/500], Loss: 0.0198\n",
      "Test Loss: 0.0202\n",
      "Epoch [414/500], Loss: 0.0195\n",
      "Test Loss: 0.0201\n",
      "Epoch [415/500], Loss: 0.0194\n",
      "Test Loss: 0.0203\n",
      "Epoch [416/500], Loss: 0.0196\n",
      "Test Loss: 0.0203\n",
      "Epoch [417/500], Loss: 0.0196\n",
      "Test Loss: 0.0202\n",
      "Epoch [418/500], Loss: 0.0196\n",
      "Test Loss: 0.0200\n",
      "Epoch [419/500], Loss: 0.0193\n",
      "Test Loss: 0.0198\n",
      "Epoch [420/500], Loss: 0.0192\n",
      "Test Loss: 0.0198\n",
      "Epoch [421/500], Loss: 0.0191\n",
      "Test Loss: 0.0198\n",
      "Epoch [422/500], Loss: 0.0191\n",
      "Test Loss: 0.0198\n",
      "Epoch [423/500], Loss: 0.0192\n",
      "Test Loss: 0.0199\n",
      "Epoch [424/500], Loss: 0.0192\n",
      "Test Loss: 0.0198\n",
      "Epoch [425/500], Loss: 0.0192\n",
      "Test Loss: 0.0199\n",
      "Epoch [426/500], Loss: 0.0192\n",
      "Test Loss: 0.0200\n",
      "Epoch [427/500], Loss: 0.0194\n",
      "Test Loss: 0.0207\n",
      "Epoch [428/500], Loss: 0.0200\n",
      "Test Loss: 0.0214\n",
      "Epoch [429/500], Loss: 0.0207\n",
      "Test Loss: 0.0227\n",
      "Epoch [430/500], Loss: 0.0220\n",
      "Test Loss: 0.0219\n",
      "Epoch [431/500], Loss: 0.0213\n",
      "Test Loss: 0.0208\n",
      "Epoch [432/500], Loss: 0.0202\n",
      "Test Loss: 0.0197\n",
      "Epoch [433/500], Loss: 0.0190\n",
      "Test Loss: 0.0203\n",
      "Epoch [434/500], Loss: 0.0197\n",
      "Test Loss: 0.0213\n",
      "Epoch [435/500], Loss: 0.0206\n",
      "Test Loss: 0.0199\n",
      "Epoch [436/500], Loss: 0.0193\n",
      "Test Loss: 0.0193\n",
      "Epoch [437/500], Loss: 0.0186\n",
      "Test Loss: 0.0201\n",
      "Epoch [438/500], Loss: 0.0194\n",
      "Test Loss: 0.0200\n",
      "Epoch [439/500], Loss: 0.0194\n",
      "Test Loss: 0.0194\n",
      "Epoch [440/500], Loss: 0.0187\n",
      "Test Loss: 0.0193\n",
      "Epoch [441/500], Loss: 0.0186\n",
      "Test Loss: 0.0196\n",
      "Epoch [442/500], Loss: 0.0190\n",
      "Test Loss: 0.0194\n",
      "Epoch [443/500], Loss: 0.0187\n",
      "Test Loss: 0.0190\n",
      "Epoch [444/500], Loss: 0.0183\n",
      "Test Loss: 0.0192\n",
      "Epoch [445/500], Loss: 0.0186\n",
      "Test Loss: 0.0194\n",
      "Epoch [446/500], Loss: 0.0188\n",
      "Test Loss: 0.0190\n",
      "Epoch [447/500], Loss: 0.0184\n",
      "Test Loss: 0.0188\n",
      "Epoch [448/500], Loss: 0.0182\n",
      "Test Loss: 0.0190\n",
      "Epoch [449/500], Loss: 0.0184\n",
      "Test Loss: 0.0188\n",
      "Epoch [450/500], Loss: 0.0183\n",
      "Test Loss: 0.0186\n",
      "Epoch [451/500], Loss: 0.0180\n",
      "Test Loss: 0.0187\n",
      "Epoch [452/500], Loss: 0.0181\n",
      "Test Loss: 0.0188\n",
      "Epoch [453/500], Loss: 0.0182\n",
      "Test Loss: 0.0187\n",
      "Epoch [454/500], Loss: 0.0181\n",
      "Test Loss: 0.0185\n",
      "Epoch [455/500], Loss: 0.0179\n",
      "Test Loss: 0.0186\n",
      "Epoch [456/500], Loss: 0.0180\n",
      "Test Loss: 0.0188\n",
      "Epoch [457/500], Loss: 0.0182\n",
      "Test Loss: 0.0185\n",
      "Epoch [458/500], Loss: 0.0180\n",
      "Test Loss: 0.0184\n",
      "Epoch [459/500], Loss: 0.0179\n",
      "Test Loss: 0.0185\n",
      "Epoch [460/500], Loss: 0.0179\n",
      "Test Loss: 0.0184\n",
      "Epoch [461/500], Loss: 0.0179\n",
      "Test Loss: 0.0184\n",
      "Epoch [462/500], Loss: 0.0178\n",
      "Test Loss: 0.0183\n",
      "Epoch [463/500], Loss: 0.0177\n",
      "Test Loss: 0.0183\n",
      "Epoch [464/500], Loss: 0.0177\n",
      "Test Loss: 0.0183\n",
      "Epoch [465/500], Loss: 0.0177\n",
      "Test Loss: 0.0181\n",
      "Epoch [466/500], Loss: 0.0175\n",
      "Test Loss: 0.0179\n",
      "Epoch [467/500], Loss: 0.0174\n",
      "Test Loss: 0.0179\n",
      "Epoch [468/500], Loss: 0.0174\n",
      "Test Loss: 0.0179\n",
      "Epoch [469/500], Loss: 0.0174\n",
      "Test Loss: 0.0179\n",
      "Epoch [470/500], Loss: 0.0174\n",
      "Test Loss: 0.0179\n",
      "Epoch [471/500], Loss: 0.0173\n",
      "Test Loss: 0.0178\n",
      "Epoch [472/500], Loss: 0.0173\n",
      "Test Loss: 0.0179\n",
      "Epoch [473/500], Loss: 0.0174\n",
      "Test Loss: 0.0180\n",
      "Epoch [474/500], Loss: 0.0175\n",
      "Test Loss: 0.0182\n",
      "Epoch [475/500], Loss: 0.0176\n",
      "Test Loss: 0.0184\n",
      "Epoch [476/500], Loss: 0.0178\n",
      "Test Loss: 0.0188\n",
      "Epoch [477/500], Loss: 0.0181\n",
      "Test Loss: 0.0187\n",
      "Epoch [478/500], Loss: 0.0181\n",
      "Test Loss: 0.0183\n",
      "Epoch [479/500], Loss: 0.0177\n",
      "Test Loss: 0.0179\n",
      "Epoch [480/500], Loss: 0.0173\n",
      "Test Loss: 0.0176\n",
      "Epoch [481/500], Loss: 0.0170\n",
      "Test Loss: 0.0177\n",
      "Epoch [482/500], Loss: 0.0171\n",
      "Test Loss: 0.0179\n",
      "Epoch [483/500], Loss: 0.0174\n",
      "Test Loss: 0.0180\n",
      "Epoch [484/500], Loss: 0.0175\n",
      "Test Loss: 0.0179\n",
      "Epoch [485/500], Loss: 0.0173\n",
      "Test Loss: 0.0177\n",
      "Epoch [486/500], Loss: 0.0172\n",
      "Test Loss: 0.0175\n",
      "Epoch [487/500], Loss: 0.0170\n",
      "Test Loss: 0.0175\n",
      "Epoch [488/500], Loss: 0.0169\n",
      "Test Loss: 0.0175\n",
      "Epoch [489/500], Loss: 0.0170\n",
      "Test Loss: 0.0176\n",
      "Epoch [490/500], Loss: 0.0171\n",
      "Test Loss: 0.0177\n",
      "Epoch [491/500], Loss: 0.0171\n",
      "Test Loss: 0.0175\n",
      "Epoch [492/500], Loss: 0.0169\n",
      "Test Loss: 0.0174\n",
      "Epoch [493/500], Loss: 0.0168\n",
      "Test Loss: 0.0172\n",
      "Epoch [494/500], Loss: 0.0167\n",
      "Test Loss: 0.0172\n",
      "Epoch [495/500], Loss: 0.0167\n",
      "Test Loss: 0.0173\n",
      "Epoch [496/500], Loss: 0.0168\n",
      "Test Loss: 0.0173\n",
      "Epoch [497/500], Loss: 0.0167\n",
      "Test Loss: 0.0172\n",
      "Epoch [498/500], Loss: 0.0167\n",
      "Test Loss: 0.0172\n",
      "Epoch [499/500], Loss: 0.0167\n",
      "Test Loss: 0.0173\n",
      "Epoch [500/500], Loss: 0.0168\n",
      "Test Loss: 0.0173\n"
     ]
    }
   ],
   "source": [
    "#basic feed forward test\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(5 * 10 * 10, 150) \n",
    "        self.relu1 = nn.ReLU()  \n",
    "        self.fc2 = nn.Linear(150, 150) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(150, 150) \n",
    "        self.relu3 = nn.ReLU() \n",
    "        self.fc4 = nn.Linear(150, 10 * 10) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.view(-1, 10, 10)  # Reshape the output to be 10x10\n",
    "\n",
    "# Create an instance of the model\n",
    "model = FullyConnectedNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_outputs = model(x_train)\n",
    "    loss = criterion(train_outputs, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(x_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Test: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr params: 135550\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Nr params: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_exmp = 0\n",
    "with torch.no_grad():\n",
    "    y  = y_test[plot_exmp].expand(1, y_test[plot_exmp].shape[0], y_test[plot_exmp].shape[1])\n",
    "    example = torch.row_stack((x_test[plot_exmp], y))\n",
    "    plot_double_trio(example)\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.title(\"Non-binarized Output\")\n",
    "    plt.imshow(model(x_test[plot_exmp].unsqueeze(0))[0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
