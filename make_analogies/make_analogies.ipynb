{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#make transformations valid for rectangles and Ls\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import pickle\n",
    "\n",
    "from make_analogies_functions import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(22)\n",
    "# im = create_image(10, shape=\"rectangle\")\n",
    "# print(im)\n",
    "# count_pixels(im, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100 #each sample is a trio of images of which each comes in various forms (analogous transformations).\n",
    "img_size = 10\n",
    "pairs_per_task = 3\n",
    "shape = \"L\" #rectangle or L\n",
    "all_images = []\n",
    "method_names = [\"Grown\", \"Moved\", \"Rotated\", \"Inverted\", \"Mirrored\", \"Close/Far Corners\", \"Close/Far Edges\", \"Stretched\", \"Shadows\", \"Gravity\", \"Count\"]\n",
    "seed_iteration = 0\n",
    "data = []\n",
    "\n",
    "for i in range(num_samples):    \n",
    "    trios = []\n",
    "    invalid_img = True\n",
    "    while invalid_img:\n",
    "        seed_iteration += 1\n",
    "        np.random.seed(seed_iteration)\n",
    "\n",
    "        #make 3 random images with rectangles\n",
    "        trio = [create_image(img_size = img_size, shape = shape) for _ in range(pairs_per_task)]\n",
    "\n",
    "        #sample parameters for analogies\n",
    "        mirror_horizontal = np.random.choice([True, False])\n",
    "        rotation_degree = np.random.choice([90, 180, 270])\n",
    "        grow_left = np.random.choice([0,0,1,2])\n",
    "        grow_right = np.random.choice([0,0,1,2])\n",
    "        grow_top = np.random.choice([0,0,1,2])\n",
    "        grow_bottom = np.random.choice([0,0,1,2])\n",
    "        move_vertical = np.random.choice([-2,-1,0,1,2])\n",
    "        move_horizontal = np.random.choice([-2,-1,0,1,2])\n",
    "        furthest_edge = np.random.choice([True, False])\n",
    "        furthest_corner = np.random.choice([True, False])\n",
    "        reverse_shadows = np.random.choice([True, False])\n",
    "        gravity_direction = np.random.choice([\"up\",\"down\",\"left\",\"right\"])\n",
    "        count_left_right = np.random.choice([True, False])\n",
    "        count_top_bottom = np.random.choice([True, False])\n",
    "\n",
    "        # Generate analogies\n",
    "        growths = [grow(img, grow_top, grow_bottom, grow_left, grow_right) for img in trio]\n",
    "        moves = [move(img, move_horizontal, move_vertical)  for img in trio]\n",
    "        rotations = [rotate_image(img, rotation_degree) for img in trio]\n",
    "        inversions = [invert_colors(img)  for img in trio]\n",
    "        mirrors = [mirror_image(img, horizontal=mirror_horizontal) for img in trio]\n",
    "        corner_cells = [paint_corner(img, furthest_corner) for img in trio]\n",
    "        edges = [paint_edge(img, furthest_edge) for img in trio]\n",
    "        stretches = [stretch_rectangle(img) for img in trio]\n",
    "        shadows = [draw_shadows(img, reverse_shadows)  for img in trio]\n",
    "        gravities = [gravity(img, gravity_direction)  for img in trio]\n",
    "        counts = [count_pixels(img, count_left_right, count_top_bottom) for img in trio]\n",
    "        \n",
    "        #check whether images violate rules (original three include duplicates; initial transformations left the canvas)\n",
    "        if np.array_equal(trio[0], trio[1]) or np.array_equal(trio[0], trio[2]) or np.array_equal(trio[1], trio[2]):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(growths[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        elif invalid_matrix(growths[0], img_size, img_size, 1):\n",
    "            invalid_img = True\n",
    "        else:\n",
    "            invalid_img = False\n",
    "    \n",
    "    transformed_trios = [growths, moves, rotations, inversions, mirrors, corner_cells, edges, stretches, shadows, gravities, counts]\n",
    "    data.append([np.stack([trio, transformed_trio]) for transformed_trio in transformed_trios])\n",
    "\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is for reformatting the df; one could e.g. slice off specific data here (e.g., for a test set with only new analogies)\n",
    "long_data = data.reshape(data.shape[0]*data.shape[1], data.shape[2], data.shape[3], data.shape[4], data.shape[5])\n",
    "long_data = long_data.reshape(long_data.shape[0], long_data.shape[1] * long_data.shape[2], long_data.shape[3], long_data.shape[4])\n",
    "nonduplicates = np.unique(long_data, axis=0) #get rid of duplicated tasks; could be stricter by also considering flipped fewshot orders as duplicated\n",
    "print(f\"{np.round(100*(1 - nonduplicates.shape[0] / long_data.shape[0]),1)}% double trios were duplicated\") \n",
    "print(long_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 2):\n",
    "    plot_double_trio(long_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"nonduplicates.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(nonduplicates, file=f)\n",
    "\n",
    "with open(\"nonduplicates_L.pkl\", \"rb\") as f:\n",
    "    nonduplicates = pickle.load(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into input (x) and output (y)\n",
    "x_data = nonduplicates[:, :-1, :, :] / 255 # All but the last channel\n",
    "y_data = nonduplicates[:, -1, :, :] / 255  # Only the last channel\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_data = torch.from_numpy(x_data).float()\n",
    "y_data = torch.from_numpy(y_data).float()\n",
    "\n",
    "# Split into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.005, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting tensors\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "batch_size = 512  # You can adjust the batch size as needed\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic feed forward test\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(5 * 10 * 10, 200) \n",
    "        self.relu1 = nn.ReLU()  \n",
    "        self.fc2 = nn.Linear(200, 200) \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.fc3 = nn.Linear(200, 200) \n",
    "        self.relu3 = nn.ReLU() \n",
    "        self.fc4 = nn.Linear(200, 10 * 10) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.view(-1, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Create an instance of the model\n",
    "model = FullyConnectedNN().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, end_factor=0.1, total_iters=num_epochs, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = model(inputs)\n",
    "        loss = criterion(train_outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(x_test)\n",
    "        test_loss = criterion(test_outputs, y_test)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Test: {test_loss.item():.4f}')\n",
    "    \n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FullyConnectedNN()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Nr params: {pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exmp = 38\n",
    "with torch.no_grad():\n",
    "    print(\"Test set example:\")\n",
    "    y  = y_test[plot_exmp].expand(1, y_test[plot_exmp].shape[0], y_test[plot_exmp].shape[1])\n",
    "    example = torch.row_stack((x_test[plot_exmp], y))\n",
    "    plot_double_trio(example)\n",
    "\n",
    "    print(\"Prediction:\")\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.title(\"Non-binarized Output\")\n",
    "    plt.imshow(model(x_test[plot_exmp].unsqueeze(0))[0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Most similar case in training data:\")\n",
    "    distance = [torch.sum(torch.abs(x_test[plot_exmp] - np.array(x_train[i]))).item() for i in range(x_train.shape[0])]\n",
    "    sim_index = np.argmin(distance)\n",
    "    y  = y_train[sim_index].expand(1, y_train[sim_index].shape[0], y_train[sim_index].shape[1])\n",
    "    plot_double_trio(torch.row_stack((x_train[sim_index], y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
